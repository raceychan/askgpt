// This file is auto-generated by @hey-api/openapi-ts

export type API = {
    HOST: string;
    PORT: number;
    API_VERSION?: string;
};

export type ActorRefs = {
    SYSTEM?: string;
    EVENTLOG?: string;
    JOURNAL?: string;
};

export type Body_auth_login = {
    settings?: (Settings | null);
    grant_type?: (string | null);
    username: string;
    password: string;
    scope?: string;
    client_id?: (string | null);
    client_secret?: (string | null);
};

export type Body_auth_signup = {
    r: SignUp;
    settings?: (Settings | null);
};

export type Body_gpt_chat = {
    req: ChatCompletionRequest;
    settings?: (Settings | null);
};

export type Body_gpt_rename_session = {
    req: SessionRenameRequest;
    settings?: (Settings | null);
};

export type Body_user_create_new_key = {
    r: CreateNewKey;
    settings?: (Settings | null);
};

/**
 * Driver-specific connection arguments
 * https://magicstack.github.io/asyncpg/current/api/index.html
 */
export type CONNECT_ARGS = {
    server_settings?: ({
    [key: string]: unknown;
} | null);
};

/**
 *     Creates a model response for the given chat conversation.
 *
 * Args:
 * messages: A list of messages comprising the conversation so far.
 * [Example Python code](https://cookbook.openai.com/examples/how_to_format_inputs_to_chatgpt_models).
 *
 * model: ID of the model to use. See the
 * [model endpoint compatibility](https://platform.openai.com/docs/models/model-endpoint-compatibility)
 * table for details on which models work with the Chat API.
 *
 * frequency_penalty: Number between -2.0 and 2.0. Positive values penalize new tokens based on their
 * existing frequency in the text so far, decreasing the model's likelihood to
 * repeat the same line verbatim.
 *
 * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/gpt/parameter-details)
 *
 *
 * logit_bias: Modify the likelihood of specified tokens appearing in the completion.
 *
 * Accepts a JSON object that maps tokens (specified by their token ID in the
 * tokenizer) to an associated bias value from -100 to 100. Mathematically, the
 * bias is added to the logits generated by the model prior to sampling. The exact
 * effect will vary per model, but values between -1 and 1 should decrease or
 * increase likelihood of selection; values like -100 or 100 should result in a ban
 * or exclusive selection of the relevant token.
 *
 * max_tokens: The maximum number of [tokens](/tokenizer) to generate in the chat completion.
 *
 * The total length of input tokens and generated tokens is limited by the model's
 * context length.
 * [Example Python code](https://cookbook.openai.com/examples/how_to_count_tokens_with_tiktoken)
 * for counting tokens.
 *
 * n: How many chat completion choices to generate for each input message.
 *
 * presence_penalty: Number between -2.0 and 2.0. Positive values penalize new tokens based on
 * whether they appear in the text so far, increasing the model's likelihood to
 * talk about new topics.
 *
 * [See more information about frequency and presence penalties.](https://platform.openai.com/docs/guides/gpt/parameter-details)
 *
 * response_format: An object specifying the format that the model must output. Used to enable JSON
 * mode.
 *
 * seed: This feature is in Beta. If specified, our system will make a best effort to
 * sample deterministically, such that repeated requests with the same `seed` and
 * parameters should return the same result. Determinism is not guaranteed, and you
 * should refer to the `system_fingerprint` response parameter to monitor changes
 * in the backend.
 *
 * stop: Up to 4 sequences where the API will stop generating further tokens.
 *
 * stream: If set, partial message deltas will be sent, like in ChatGPT. Tokens will be
 * sent as data-only
 * [server-sent events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#Event_stream_format)
 * as they become available, with the stream terminated by a `data: [DONE]`
 * message.
 * [Example Python code](https://cookbook.openai.com/examples/how_to_stream_completions).
 *
 * temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will
 * make the output more random, while lower values like 0.2 will make it more
 * focused and deterministic.
 *
 * We generally recommend altering this or `top_p` but not both.
 *
 * tool_choice: Controls which (if any) function is called by the model. `none` means the model
 * will not call a function and instead generates a message. `auto` means the model
 * can pick between generating a message or calling a function. Specifying a
 * particular function via
 * `{"type: "function", "function": {"name": "my_function"}}` forces the model to
 * call that function.
 *
 * `none` is the default when no functions are present. `auto` is the default if
 * functions are present.
 *
 * tools: A list of tools the model may call. Currently, only functions are supported as a
 * tool. Use this to provide a list of functions the model may generate JSON inputs
 * for.
 *
 * top_p: An alternative to sampling with temperature, called nucleus sampling, where the
 * model considers the results of the tokens with top_p probability mass. So 0.1
 * means only the tokens comprising the top 10% probability mass are considered.
 *
 * We generally recommend altering this or `temperature` but not both.
 *
 * user: A unique identifier representing your end-user, which can help OpenAI to monitor
 * and detect abuse.
 * [Learn more](https://platform.openai.com/docs/guides/safety-best-practices/end-user-ids).
 *
 * extra_headers: Send extra headers
 *
 * extra_query: Add additional query parameters to the request
 *
 * extra_body: Add additional JSON properties to the request
 *
 * timeout: Override the client-level default timeout for this request, in seconds
 */
export type ChatCompletionRequest = {
    question: string;
    role: 'system' | 'user' | 'assistant' | 'function';
    model?: 'gpt-3.5-turbo' | 'gpt-3.5-turbo-16k' | 'gpt-4' | 'gpt-4-32k' | 'gpt-4-1106-preview' | 'gpt-4-vision-preview';
    frequency_penalty?: (number | null);
    logit_bias?: ({
    [key: string]: (number);
} | null);
    max_tokens?: (number | null);
    n?: (number | null);
    presence_penalty?: (number | null);
    response_format?: unknown;
    seed?: (number | null);
    stop?: (string | Array<(string)> | null);
    stream?: (boolean | null);
    temperature?: (number | null);
    tool_choice?: unknown;
    tools?: (Array<unknown> | null);
    top_p?: (number | null);
    user?: (string | null);
    extra_headers?: ({
    [key: string]: (string | false);
} | null);
    extra_query?: ({
    [key: string]: unknown;
} | null);
    extra_body?: ({
    [key: string]: unknown;
} | null);
    timeout?: (number | null);
};

export type role = 'system' | 'user' | 'assistant' | 'function';

export type model = 'gpt-3.5-turbo' | 'gpt-3.5-turbo-16k' | 'gpt-4' | 'gpt-4-32k' | 'gpt-4-1106-preview' | 'gpt-4-vision-preview';

export type CreateNewKey = {
    api_key: string;
    api_type?: SupportedGPTs;
};

/**
 * Perhaps separate this for PGDB, SqliteDB, MysqlDB etc.
 */
export type DB = {
    DIALECT: string;
    DRIVER: string;
    USER: string;
    PASSWORD: string;
    HOST?: string;
    PORT?: number;
    DATABASE: (string | ':memory:');
    ISOLATION_LEVEL: SQL_ISOLATIONLEVEL;
    ENGINE_ECHO?: boolean;
    connect_args?: (CONNECT_ARGS | null);
    execution_options?: (ExeuctionOptions | null);
};

export type EventRecord = {
    EVENT_FETCH_INTERVAL?: number;
};

/**
 * Sqlalchemy engine-specific options
 */
export type ExeuctionOptions = {
    [key: string]: unknown;
};

export type HTTPValidationError = {
    detail?: Array<ValidationError>;
};

export type KeySpace = [
    string
];

export type KeySpaces = {
    APP: KeySpace;
};

export type OpenAIClient = {
    TIMEOUT?: number;
    MAX_RETRIES?: number;
};

export type PublicUserInfo = {
    user_id: string;
    user_name: string;
    email: string;
};

export type PulibcSessionInfo = {
    session_id: string;
    session_name: string;
};

export type Redis = {
    SCHEME?: 'redis' | 'rediss' | 'unix';
    HOST: string;
    PORT: (number | string);
    DB: (number | string);
    TOKEN_BUCKET_SCRIPT?: string;
    MAX_CONNECTIONS?: number;
    DECODE_RESPONSES?: boolean;
    SOCKET_TIMEOUT?: number;
    SOCKET_CONNECT_TIMEOUT?: number;
    keyspaces: KeySpaces;
};

export type SCHEME = 'redis' | 'rediss' | 'unix';

export type SQL_ISOLATIONLEVEL = 'SERIALIZABLE' | 'REPEATABLE READ' | 'READ COMMITTED' | 'READ UNCOMMITTED' | 'AUTOCOMMIT';

export type SUPPORTED_ALGORITHMS = 'A192GCM' | 'HS384' | 'A256GCM' | 'RS512' | 'RSA1_5' | 'RS256' | 'A128KW' | 'ES512' | 'dir' | 'RSA-OAEP' | 'HS512' | 'RS384' | 'RSA-OAEP-256' | 'A256CBC-HS512' | 'ES384' | 'A256KW' | 'ES256' | 'HS256' | 'A128CBC-HS256' | 'A192CBC-HS384' | 'A128GCM' | 'A192KW';

export type Security = {
    SECRET_KEY: string;
    ALGORITHM: SUPPORTED_ALGORITHMS;
    ACCESS_TOKEN_EXPIRE_MINUTES?: number;
    CORS_ORIGINS: Array<(string)>;
};

export type SessionRenameRequest = {
    name: string;
};

export type Settings = {
    RUNTIME_ENV: 'dev' | 'prod' | 'test';
    db: DB;
    actor_refs: ActorRefs;
    security: Security;
    api: API;
    redis: Redis;
    throttling: Throttling;
    event_record: EventRecord;
    openai_client: OpenAIClient;
};

export type RUNTIME_ENV = 'dev' | 'prod' | 'test';

export type SignUp = {
    user_name?: string;
    email: string;
    password: string;
};

export type SupportedGPTs = 'openai';

export type Throttling = {
    USER_MAX_REQUEST_PER_MINUTE: number;
    USER_MAX_REQUEST_DURATION_MINUTE: number;
};

export type TokenResponse = {
    access_token: string;
    token_type?: 'bearer';
};

export type token_type = 'bearer';

export type UserAuth = {
    user_id: string;
    role?: UserRoles;
    credential: UserCredential;
    last_login: string;
    is_active?: boolean;
};

export type UserCredential = {
    user_name?: string;
    user_email: string;
    hash_password: string;
};

export type UserRoles = 'admin' | 'user';

export type ValidationError = {
    loc: Array<(string | number)>;
    msg: string;
    type: string;
};

export type LoginData = {
    body: Body_auth_login;
};

export type LoginResponse = (TokenResponse);

export type LoginError = (HTTPValidationError);

export type SignupData = {
    body: Body_auth_signup;
};

export type SignupResponse = (unknown);

export type SignupError = (HTTPValidationError);

export type FindUserByEmailData = {
    body?: (Settings | null);
    query: {
        email: string;
    };
};

export type FindUserByEmailResponse = (PublicUserInfo);

export type FindUserByEmailError = (HTTPValidationError);

export type GetPublicUserData = {
    body?: (Settings | null);
};

export type GetPublicUserResponse = (PublicUserInfo);

export type GetPublicUserError = (HTTPValidationError);

export type GetUserDetailData = {
    body?: (Settings | null);
    path: {
        user_id: string;
    };
};

export type GetUserDetailResponse = ((UserAuth | null));

export type GetUserDetailError = (HTTPValidationError);

export type DeleteUserData = {
    body?: (Settings | null);
};

export type DeleteUserResponse = (unknown);

export type DeleteUserError = (HTTPValidationError);

export type CreateNewKeyData = {
    body: Body_user_create_new_key;
};

export type CreateNewKeyResponse = (unknown);

export type CreateNewKeyError = (HTTPValidationError);

export type ListSessionsData = {
    body?: (Settings | null);
};

export type ListSessionsResponse = (Array<PulibcSessionInfo>);

export type ListSessionsError = (HTTPValidationError);

export type CreateSessionData = {
    body?: (Settings | null);
};

export type CreateSessionResponse = (unknown);

export type CreateSessionError = (HTTPValidationError);

export type GetSessionData = {
    body?: (Settings | null);
    path: {
        session_id: string;
    };
};

export type GetSessionResponse = (unknown);

export type GetSessionError = (HTTPValidationError);

export type RenameSessionData = {
    body: Body_gpt_rename_session;
    path: {
        session_id: string;
    };
};

export type RenameSessionResponse = (unknown);

export type RenameSessionError = (HTTPValidationError);

export type DeleteSessionData = {
    body?: (Settings | null);
    path: {
        session_id: string;
    };
};

export type DeleteSessionResponse = (unknown);

export type DeleteSessionError = (HTTPValidationError);

export type ChatData = {
    body: Body_gpt_chat;
    path: {
        session_id: string;
    };
};

export type ChatResponse = (unknown);

export type ChatError = (HTTPValidationError);

export type LambdaResponse = (unknown);

export type LambdaError = unknown;